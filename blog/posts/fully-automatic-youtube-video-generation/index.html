<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="HandheldFriendly" content="true">
  <meta name="title" content="Nicholas Ficara - Developper Portfolio" />
  <meta name="description"
    content="Nicholas Ficara's personal portfolio and blog. A passionate young developper from Ottawa.">

  <meta name="robots">
  <meta name="googlebot">

  <title>Nicholas Ficara</title>
  <link rel="shortcut icon" href="/favicon.ico" />
  <link rel="stylesheet" href="/css/index.css">
  <link rel="stylesheet" href="/css/blog.css">
</head>

<body>
  <menu id="menu">
    <a class="pointer" href="/">
      <img alt="Initials NF" src="/assets/nf4.png" style="width: 13vw; filter: saturate(0.9);" />
    </a>
    <nav id="nav">
      <a class="link" href="/blog">Back to Articles</a>
      <a class="link" href="/">Return Home</a>
    </nav>
    <footer>
      <div style="display: flex; justify-content: space-around; flex-wrap: wrap;">
        <a class="icon-link" rel="noreferrer nofollow" target="_blank" href="mailto:nick@nicholasficara.dev">
          <img class="icon-small invert" alt="envelope" src="/assets/envelope.svg" />
        </a>
        <a class="icon-link" rel="noreferrer nofollow" target="_blank" href="https://github.com/Green-Robot-Dev-Studios">
          <img class="icon-small invert" alt="github logo" src="/assets/github.svg" />
        </a>
        <a class="icon-link" rel="noreferrer nofollow" target="_blank" href="https://www.linkedin.com/in/nicholasficara/">
          <img class="icon-small invert" alt="linkedin logo" src="/assets/linkedin-in-brands.svg" />
        </a>
        <a class="icon-link" rel="noreferrer nofollow" target="_blank" href="/assets/Nicholas Ficara - Resume.pdf">
          <img class="icon-small invert" alt="cv logo" src="/assets/file-alt.svg" />
        </a>
      </div>
      <p style="white-space: nowrap;">Â© Nicholas Ficara</p>
    </footer>
  </menu>

  <div id="container">
  
<section>
  <h1>Making YouTube Videos Completely Automatically</h1>
  <h4>Wed, 09 Sep 2020 </h4>
  <h4>Nicholas Ficara</h4>
</section>

<p>I came across this type of channel on YouTube called Reddit readers. They use a text to speech software or a human voice over to read Reddit posts. There are plenty of them if you search up <code>reddit reader</code>. I realized that this is probably possible to do without any human interaction whatsoever.</p>
<h2>What I Built</h2>
<p>This was the final product: https://youtu.be/8QHTimxYGes. I simply put in a Reddit link and it did the rest. With a bit more polish like an intro, it could be really good. I decided against going all the way because there are already enough of these Reddit readers and we <em>really</em> don't need another one.</p>
<h2>How I Built It</h2>
<p>This was a surprisingly easy project. Here is how it went:</p>
<ol>
<li>Use the Reddit api to get the content and title of the given post.</li>
<li>Separate the post into chunks of n words.</li>
<li>Pass each chunk through a text to speech algorithm.</li>
<li>Generate a png image with the text on it using python imaging library.</li>
<li>Use librosa to piece together the video with the correct timings.</li>
<li>Export the video.</li>
<li>Post to YouTube (I didn't do this part)</li>
</ol>
<h2>Conclusion</h2>
<p>I enjoyed building this, and it was quite satisfying to send to my friends. This could totally replace the Reddit readers that use TTS software. It's not that complicated and could be expanded to have a dynamic image in the background like a GIF file.</p>
<p>The code is not on GitHub, mainly because there are a lot of dependencies, and it's not the best quality code, but if someone wants to use it or build on it, please go right ahead!</p>
<pre><code class="language-python">import praw
from PIL import Image, ImageDraw, ImageFont
from gtts import gTTS
import cv2
import os
from mutagen.mp3 import MP3
from moviepy.editor import *
import textwrap
from textwrap import wrap
import tts.sapi
import librosa

voice = tts.sapi.Sapi()
reddit = praw.Reddit(client_id='', client_secret='', user_agent='')
hot_posts = reddit.subreddit('EntitledParents').hot(limit=10)
i = 0
fetched_posts = []
for post in hot_posts:
    fetched_posts.append(post.selftext)
    i = i+1
to_say = fetched_posts[2].split(&quot; &quot;)

to_say = wrap(fetched_posts[2], 420)

fnt = ImageFont.truetype('arial.ttf', 50)

chunk_num = 0
for chunk in to_say:
    if chunk == &quot;&quot;:
        continue

    img = Image.new('RGBA', (1920, 1080), color = (0, 0, 0, 0))
    d = ImageDraw.Draw(img)

    chunk_wrapped = textwrap.wrap(chunk, width=50)

    
    current_h, pad = 200, 10
    for line in chunk_wrapped:
        w, h = d.textsize(line, font=fnt)
        d.text(((1920 - w) / 2, current_h), line, font=fnt)
        current_h += h + pad

    
    bg = Image.open(&quot;bg.png&quot;)
    bg.paste(img, (0, 0), img)
    bg.save('images/' + str(chunk_num) + '.png')

    voice.create_recording(str(chunk_num) + '.wav', chunk)
    
    chunk_num = chunk_num + 1

voice.create_recording('full.wav', fetched_posts[2])

image_folder = 'images'
video_name = 'video.mp4'

images = [img for img in os.listdir(image_folder) if img.endswith(&quot;.png&quot;)]
frame = cv2.imread(os.path.join(image_folder, images[0]))
height, width, layers = frame.shape
fourcc = cv2.VideoWriter_fourcc('F', 'M', 'P', '4')
video = cv2.VideoWriter(video_name, fourcc, 24, (width,height))

for image in images:
    for i in range(int(librosa.get_duration(filename=image.split(&quot;.&quot;)[0] + '.wav'))*24):
        video.write(cv2.imread(os.path.join(image_folder, image)))

cv2.destroyAllWindows()
video.release()
print(&quot;Final Export&quot;)
movie = VideoFileClip(&quot;video.mp4&quot;)
movie.write_videofile(&quot;finished_video.mp4&quot;, audio=&quot;full.wav&quot;, threads = 4, logger = None)


</code></pre>

  </div>
</body>

</html>